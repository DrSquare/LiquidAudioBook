# Flask Configuration
FLASK_ENV=development
FLASK_DEBUG=false
FLASK_PORT=5001

# Liquid AI LFM2 Models Configuration
# Vision/Image Model - LLaVA-based vision model for image text extraction
IMAGE_MODEL_PATH=hf.co/LiquidAI/LFM2-VL-3B-GGUF:F16
IMAGE_MODEL_NAME=LFM2-VL-3B

# Text Extractor Model - For text refinement and extraction
EXTRACTOR_MODEL_PATH=hf.co/LiquidAI/LFM2-1.2B-Extract-GGUF:F16
EXTRACTOR_MODEL_NAME=LFM2-1.2B-Extract

# Audio Models - For TTS audio generation
AUDIO_MODEL_PATH=/path/to/lfm2-audio-1.5b-f16.gguf
AUDIO_MMPROJ_PATH=/path/to/mmproj-model-f16.gguf
AUDIO_DECODER_PATH=/path/to/audiodecoder-model-f16.gguf

# Ollama Configuration (if using Ollama server)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TIMEOUT=120000

# TTS Configuration (fallback or hybrid)
TTS_ENGINE=pyttsx3
TTS_RATE=150
TTS_VOICE=default

# Express Backend (for reference)
EXPRESS_BACKEND_URL=http://localhost:5000

# Model Download Settings
AUTO_DOWNLOAD_MODELS=false
MODELS_CACHE_DIR=./models
